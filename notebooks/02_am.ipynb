{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the project root to the path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.utils import extract_trailing_numbers, set_seed\n",
    "import flowmol\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from true_reward.dxtb_simulation import compute_energy, compute_energy_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(config: OmegaConf, model: flowmol.FlowMol, device: torch.device):\n",
    "    new_molecules = model.sample_random_sizes(\n",
    "        n_molecules = config.num_samples, \n",
    "        n_timesteps = config.num_integration_steps + 1, \n",
    "        device = device,\n",
    "    )\n",
    "    return new_molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gen_model(flow_model: str, device: torch.device):\n",
    "    # Load - Flow Model\n",
    "    gen_model = flowmol.load_pretrained(flow_model)\n",
    "    gen_model.to(device)\n",
    "    return gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Run ALM with optional parameter overrides\")\n",
    "    # Settings\n",
    "    parser.add_argument(\"--config\", type=str, default=\"../configs/adjoint_matching.yaml\",\n",
    "                        help=\"Path to config file\")\n",
    "    parser.add_argument(\"--save_model\", action='store_true',\n",
    "                        help=\"Save the model, default: false\")\n",
    "    parser.add_argument(\"--save_samples\", action='store_true',\n",
    "                        help=\"Create animation of the samples and save the samples, default: false\")\n",
    "    parser.add_argument(\"--save_plots\", action='store_true',\n",
    "                        help=\"Save plots of rewards and constraints, default: false\")\n",
    "    parser.add_argument(\"--plotting_freq\", type=int,\n",
    "                        help=\"Plotting frequency\")\n",
    "    # FlowMol arguments\n",
    "    flowmol_choices = ['geom_ctmc', 'geom_gaussian']\n",
    "    parser.add_argument('--flow_model', type=str, choices=flowmol_choices,\n",
    "                        help='pretrained model to be used')\n",
    "    # Adjoint Matching Parameters\n",
    "    parser.add_argument(\"--reward_lambda\", type=float,\n",
    "                        help=\"Override reward_lambda in config\")\n",
    "    parser.add_argument(\"--lr\", type=float,\n",
    "                        help=\"Override adjoint_matching.lr in config\")\n",
    "    parser.add_argument(\"--clip_grad_norm\",  type=float,\n",
    "                        help=\"Override adjoint_matching.clip_grad_norm in config\")\n",
    "    parser.add_argument(\"--batch_size\", type=int,\n",
    "                        help=\"Override adjoint_matching.batch_size in config\")\n",
    "    parser.add_argument(\"--samples_per_update\", type=int,\n",
    "                        help=\"Override adjoint_matching.num_samples in config\")\n",
    "    parser.add_argument(\"--num_integration_steps\", type=int,\n",
    "                        help=\"Override adjoint_matching.num_integration_steps in config\")\n",
    "    parser.add_argument(\"--finetune_steps\", type=int,\n",
    "                        help=\"Override adjoint_matching.finetune_steps in config\")\n",
    "    parser.add_argument(\"--num_iterations\", type=int,\n",
    "                        help=\"Override number of iterations\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "sys.argv = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config_with_args(config, args):\n",
    "    # FlowMol arguments\n",
    "    if args.flow_model is not None:\n",
    "        config.flowmol.model = args.flow_model\n",
    "    # Adjoint Matching Parameters\n",
    "    if args.reward_lambda is not None:\n",
    "        config.reward_lambda = args.reward_lambda\n",
    "    if args.lr is not None:\n",
    "        config.adjoint_matching.lr = args.lr\n",
    "    if args.clip_grad_norm is not None:\n",
    "        config.adjoint_matching.clip_grad_norm = args.clip_grad_norm\n",
    "    if args.batch_size is not None:\n",
    "        config.adjoint_matching.batch_size = args.batch_size\n",
    "    if args.samples_per_update is not None:\n",
    "        config.adjoint_matching.sampling.num_samples = args.samples_per_update\n",
    "    if args.num_integration_steps is not None:\n",
    "        config.adjoint_matching.sampling.num_integration_steps = args.num_integration_steps\n",
    "    if args.finetune_steps is not None:\n",
    "        config.adjoint_matching.finetune_steps = args.finetune_steps\n",
    "    if args.num_iterations is not None:\n",
    "        config.adjoint_matching.num_iterations = args.num_iterations\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse command line arguments\n",
    "args = parse_args()\n",
    "\n",
    "# Load config from file\n",
    "config_path = Path(args.config)\n",
    "config = OmegaConf.load(config_path)\n",
    "\n",
    "# Update config with command line arguments\n",
    "config = update_config_with_args(config, args)\n",
    "\n",
    "# Setup - Seed and device and root directory\n",
    "set_seed(config.seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "root_dir = Path(config.root) / Path(config.experiment)\n",
    "\n",
    "# Settings\n",
    "if args.plotting_freq is None:\n",
    "    args.plotting_freq = max(config.adjoint_matching.num_iterations // 20, 1)\n",
    "\n",
    "# General Parameters\n",
    "flowmol_model = config.flow_model\n",
    "\n",
    "# Adjoint Matching Parameters\n",
    "reward_lambda = config.reward_lambda\n",
    "learning_rate = config.adjoint_matching.lr\n",
    "clip_grad_norm = config.adjoint_matching.clip_grad_norm\n",
    "traj_samples_per_stage = config.adjoint_matching.sampling.num_samples\n",
    "traj_len = config.adjoint_matching.sampling.num_integration_steps\n",
    "finetune_steps = config.adjoint_matching.finetune_steps\n",
    "num_iterations = config.adjoint_matching.num_iterations\n",
    "\n",
    "config.adjoint_matching.sampling.sampler_type = \"memoryless\"\n",
    "config.reward_sampling.sampler_type = \"euler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n",
      "verbose: false\n",
      "root: /Users/svlg/MasterThesis/v02/\n",
      "experiment: first_test\n",
      "flow_model: qm9_ctmc\n",
      "reward_lambda: 100\n",
      "adjoint_matching:\n",
      "  num_iterations: 50\n",
      "  batch_size: 6\n",
      "  clip_grad_norm: 0.5\n",
      "  clip_loss: 100000.0\n",
      "  lr: 5.0e-07\n",
      "  finetune_steps: 2\n",
      "  sampling:\n",
      "    sampler_type: memoryless\n",
      "    num_samples: 24\n",
      "    num_integration_steps: 40\n",
      "reward_sampling:\n",
      "  sampler_type: euler\n",
      "  num_samples: 20\n",
      "  num_integration_steps: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Gen Model\n",
    "gen_model = setup_gen_model(config.flow_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_fn(x_new):\n",
    "    return compute_energy(x_new, reward_lambda, device=device)\n",
    "\n",
    "def grad_reward_fn(x_new):\n",
    "    with torch.enable_grad():\n",
    "        gradients = compute_energy_grad(x_new, reward_lambda, device=device)\n",
    "        return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetuning.flow_adjoint import AdjointMatchingFinetuningTrainerFlowMol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up - Adjoint Matching       \n",
    "trainer = AdjointMatchingFinetuningTrainerFlowMol(\n",
    "    config = config.adjoint_matching,\n",
    "    model = copy.deepcopy(gen_model),\n",
    "    base_model = copy.deepcopy(gen_model),\n",
    "    grad_reward_fn = grad_reward_fn,\n",
    "    device = device,\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store loss and rewards\n",
    "losses = []\n",
    "rewards = []\n",
    "if args.save_samples:\n",
    "    new_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.save_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Samples\n",
    "new_molecules = sampling(\n",
    "    config.reward_sampling,\n",
    "    copy.deepcopy(gen_model),\n",
    "    device=device\n",
    ")\n",
    "if args.save_samples:\n",
    "    new_samples.extend(dgl.unbatch(new_molecules.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute appropriate reward for evaluation\n",
    "reward = reward_fn(x_new).item()\n",
    "rewards.append(reward/(reward_lambda+1e-8))\n",
    "current_best_reward = rewards[-1]\n",
    "best_epoch = 0\n",
    "rewards[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run finetuning loop\n",
    "with tqdm(range(1, num_iterations + 1), desc=\"Finetuning Progress\", dynamic_ncols=True) as pbar:\n",
    "    for i in pbar:\n",
    "\n",
    "        # Solves lean adjoint ODE to create dataset\n",
    "        dataset = trainer.sample_dataset()\n",
    "        \n",
    "        # Fine-tune the model with adjoint matching loss\n",
    "        loss = trainer.finetune(dataset, steps=config.adjoint_matching.finetune_steps, verbose=False)\n",
    "        losses.append(loss/(reward_lambda+1e-8)/(traj_len//2))\n",
    "        \n",
    "        # Generate Samples\n",
    "        x_new = sampling(\n",
    "            config.reward_sampling,\n",
    "            copy.deepcopy(gen_model),\n",
    "            device=device\n",
    "        )\n",
    "        if args.save_samples:\n",
    "            new_samples.append(x_new.detach().cpu().numpy())\n",
    "\n",
    "        # Compute appropriate reward for evaluation\n",
    "        tmp_reward = reward_fn(x_new).item()\n",
    "        rewards.append(tmp_reward/(reward_lambda+1e-8))\n",
    "\n",
    "        if rewards[-1] > current_best_reward:\n",
    "            current_best_reward = rewards[-1]\n",
    "            best_epoch = i\n",
    "\n",
    "        elif i % (args.plotting_freq*4) == 0:\n",
    "            print(f\"Iteration {i}: Loss: {losses[-1]:.4f}, Reward: {rewards[-1]:.4f}\", flush=True)\n",
    "            print(f\"Best reward: {current_best_reward:.4f} at epoch {best_epoch}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rewards and losses\n",
    "tmp_data = [rewards, losses]\n",
    "tmp_titles = [\"Rewards\", \"Losses\"]\n",
    "plot_graphs(tmp_data, tmp_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
