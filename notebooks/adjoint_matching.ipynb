{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2da5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import wandb\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils.utils import extract_trailing_numbers, seed_everything\n",
    "\n",
    "import flowmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f725cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(\n",
    "        config: OmegaConf,\n",
    "        model: flowmol.FlowMol,\n",
    "        xt_traj: bool = False,\n",
    "        ep_traj: bool = False, \n",
    "        device: torch.device = None\n",
    "    ):\n",
    "    new_molecules = model.sample_random_sizes(\n",
    "        n_molecules = config.num_samples, \n",
    "        n_timesteps = config.num_integration_steps,\n",
    "        xt_traj=xt_traj,\n",
    "        ep_traj=ep_traj,\n",
    "        device = device,\n",
    "    )\n",
    "    return new_molecules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1daa1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gen_model(flow_model: str, device: torch.device):\n",
    "    # Load - Flow Model\n",
    "    gen_model = flowmol.load_pretrained(flow_model)\n",
    "    gen_model.to(device)\n",
    "    return gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fb6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Run ALM with optional parameter overrides\")\n",
    "    # Settings\n",
    "    parser.add_argument(\"--config\", type=str, default=\"configs/adjoint_matching.yaml\",\n",
    "                        help=\"Path to config file\")\n",
    "    parser.add_argument(\"--use_wandb\", action='store_true',\n",
    "                        help=\"Use wandb, default: false\")\n",
    "    parser.add_argument(\"--verbose\", action='store_true', \n",
    "                        help=\"Verbose output, default: false\")\n",
    "    parser.add_argument(\"--save_model\", action='store_true',\n",
    "                        help=\"Save the model, default: false\")\n",
    "    parser.add_argument(\"--save_samples\", action='store_true',\n",
    "                        help=\"Create animation of the samples and save the samples, default: false\")\n",
    "    parser.add_argument(\"--save_plots\", action='store_true',\n",
    "                        help=\"Save plots of rewards and constraints, default: false\")\n",
    "    parser.add_argument(\"--plotting_freq\", type=int,\n",
    "                        help=\"Plotting frequency\")\n",
    "    # FlowMol arguments\n",
    "    flowmol_choices = ['qm9_ctmc', 'qm9_gaussian', 'qm9_simplexflow', 'qm9_dirichlet']\n",
    "    parser.add_argument('--flow_model', type=str, choices=flowmol_choices,\n",
    "                        help='pretrained model to be used')\n",
    "    parser.add_argument(\"--reward_lambda\", type=float,\n",
    "                        help=\"Override reward_lambda in config\")\n",
    "    parser.add_argument(\"--lr\", type=float,\n",
    "                        help=\"Override adjoint_matching.lr in config\")\n",
    "    parser.add_argument(\"--clip_grad_norm\",  type=float,\n",
    "                        help=\"Override adjoint_matching.clip_grad_norm in config\")\n",
    "    parser.add_argument(\"--batch_size\", type=int,\n",
    "                        help=\"Override adjoint_matching.batch_size in config\")\n",
    "    parser.add_argument(\"--samples_per_update\", type=int,\n",
    "                        help=\"Override adjoint_matching.num_samples in config\")\n",
    "    parser.add_argument(\"--num_integration_steps\", type=int,\n",
    "                        help=\"Override adjoint_matching.num_integration_steps in config\")\n",
    "    parser.add_argument(\"--finetune_steps\", type=int,\n",
    "                        help=\"Override adjoint_matching.finetune_steps in config\")\n",
    "    parser.add_argument(\"--num_iterations\", type=int,\n",
    "                        help=\"Override number of iterations\")\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9175cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32669a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config_with_args(config, args):\n",
    "    # FlowMol arguments\n",
    "    if args.flow_model is not None:\n",
    "        config.flowmol.model = args.flow_model\n",
    "    # Adjoint Matching Parameters\n",
    "    if args.reward_lambda is not None:\n",
    "        config.reward_lambda = args.reward_lambda\n",
    "    if args.lr is not None:\n",
    "        config.adjoint_matching.lr = args.lr\n",
    "    if args.clip_grad_norm is not None:\n",
    "        config.adjoint_matching.clip_grad_norm = args.clip_grad_norm\n",
    "    if args.batch_size is not None:\n",
    "        config.adjoint_matching.batch_size = args.batch_size\n",
    "    if args.samples_per_update is not None:\n",
    "        config.adjoint_matching.sampling.num_samples = args.samples_per_update\n",
    "    if args.num_integration_steps is not None:\n",
    "        config.adjoint_matching.sampling.num_integration_steps = args.num_integration_steps\n",
    "    if args.finetune_steps is not None:\n",
    "        config.adjoint_matching.finetune_steps = args.finetune_steps\n",
    "    if args.num_iterations is not None:\n",
    "        config.adjoint_matching.num_iterations = args.num_iterations\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb320f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start ---\n",
      "Finetuning qm9_ctmc on QM9\n",
      "Start time: 2025-04-23 11:32:06\n",
      "Device: cpu\n",
      "--- Config ---\n",
      "Adjoint Matching Parameters\n",
      "\treward_lambda: 100000\n",
      "\tlr: 5e-06\n",
      "\tclip_grad_norm: 0.7\n",
      "\tsampling.num_samples: 100\n",
      "\tsampling.num_integration_steps: 40\n",
      "\tfinetune_steps: 5\n",
      "\tnum_iterations: 400\n"
     ]
    }
   ],
   "source": [
    "# Parse command line arguments\n",
    "args = parse_args()\n",
    "\n",
    "# Load config from file\n",
    "config_path = Path(args.config)\n",
    "config = OmegaConf.load(config_path)\n",
    "\n",
    "# Update config with command line arguments\n",
    "config = update_config_with_args(config, args)\n",
    "\n",
    "# Setup - Seed and device and root directory\n",
    "seed_everything(config.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "root_dir = Path(config.root) / Path(config.dataset)\n",
    "\n",
    "# Settings\n",
    "config.verbose = args.verbose\n",
    "if args.plotting_freq is None:\n",
    "    args.plotting_freq = config.adjoint_matching.num_iterations // 20\n",
    "\n",
    "# General Parameters\n",
    "flowmol_model = config.flow_model\n",
    "dataset = config.dataset\n",
    "\n",
    "# Adjoint Matching Parameters\n",
    "reward_lambda = config.reward_lambda\n",
    "learning_rate = config.adjoint_matching.lr\n",
    "clip_grad_norm = config.adjoint_matching.clip_grad_norm\n",
    "traj_samples_per_stage = config.adjoint_matching.sampling.num_samples\n",
    "traj_len = config.adjoint_matching.sampling.num_integration_steps\n",
    "finetune_steps = config.adjoint_matching.finetune_steps\n",
    "num_iterations = config.adjoint_matching.num_iterations\n",
    "\n",
    "config.adjoint_matching.sampling.sampler_type = \"memoryless\"\n",
    "config.reward_sampling.sampler_type = \"euler\"\n",
    "\n",
    "print(f\"--- Start ---\", flush=True)\n",
    "# Setup - WandB\n",
    "if args.use_wandb:\n",
    "    wandb.init()\n",
    "    run_name = wandb.run.name  # e.g., \"olive-sweep-229\"\n",
    "    run_number = extract_trailing_numbers(run_name)  # e.g., 229\n",
    "    run_id = wandb.run.id   # e.g., \"ame6uc42\"\n",
    "    sweep_id = wandb.run.sweep_id if wandb.run.sweep_id else \"No_sweep\"\n",
    "    print(f\"Run #{run_number} - ID: {run_id}\", flush=True)\n",
    "\n",
    "# Prints\n",
    "print(f\"Finetuning {flowmol_model} on {dataset}\", flush=True)\n",
    "start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Start time: {start_time}\", flush=True)\n",
    "print(f\"Device: {device}\", flush=True)\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"--- Config ---\", flush=True)\n",
    "\n",
    "print(f\"Adjoint Matching Parameters\", flush=True)\n",
    "print(f\"\\treward_lambda: {reward_lambda}\", flush=True)\n",
    "print(f\"\\tlr: {learning_rate}\", flush=True)\n",
    "print(f\"\\tclip_grad_norm: {clip_grad_norm}\", flush=True)\n",
    "print(f\"\\tsampling.num_samples: {traj_samples_per_stage}\", flush=True)\n",
    "print(f\"\\tsampling.num_integration_steps: {traj_len}\", flush=True)\n",
    "print(f\"\\tfinetune_steps: {finetune_steps}\", flush=True)\n",
    "print(f\"\\tnum_iterations: {num_iterations}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f67bcca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.reward_sampling.num_samples = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Gen Model\n",
    "gen_model = setup_gen_model(config.flow_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60d1defb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sampler_type': 'euler', 'num_samples': 5, 'data_dim': 2, 'num_integration_steps': 40}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.reward_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbc305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    }
   ],
   "source": [
    "# # Generate Samples\n",
    "# x_new = sampling(\n",
    "#     config.reward_sampling,\n",
    "#     copy.deepcopy(gen_model),\n",
    "#     device=device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90d28881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 18, 15])\n",
      "edge_idxs_dict: {15: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,\n",
      "          4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
      "          6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
      "          9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 12, 12, 13,  1,  2,  3,\n",
      "          4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  2,  3,  4,  5,  6,  7,  8,\n",
      "          9, 10, 11, 12, 13, 14,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
      "          4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  5,  6,  7,  8,  9, 10, 11,\n",
      "         12, 13, 14,  6,  7,  8,  9, 10, 11, 12, 13, 14,  7,  8,  9, 10, 11, 12,\n",
      "         13, 14,  8,  9, 10, 11, 12, 13, 14,  9, 10, 11, 12, 13, 14, 10, 11, 12,\n",
      "         13, 14, 11, 12, 13, 14, 12, 13, 14, 13, 14, 14],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  2,  3,  4,  5,\n",
      "          6,  7,  8,  9, 10, 11, 12, 13, 14,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
      "         12, 13, 14,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  5,  6,  7,  8,\n",
      "          9, 10, 11, 12, 13, 14,  6,  7,  8,  9, 10, 11, 12, 13, 14,  7,  8,  9,\n",
      "         10, 11, 12, 13, 14,  8,  9, 10, 11, 12, 13, 14,  9, 10, 11, 12, 13, 14,\n",
      "         10, 11, 12, 13, 14, 11, 12, 13, 14, 12, 13, 14, 13, 14, 14,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,\n",
      "          6,  6,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  9,  9,  9,\n",
      "          9,  9, 10, 10, 10, 10, 11, 11, 11, 12, 12, 13]]), 18: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,\n",
      "          3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
      "          6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "          8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9, 10,\n",
      "         10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13,\n",
      "         13, 13, 13, 14, 14, 14, 15, 15, 16,  1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
      "         10, 11, 12, 13, 14, 15, 16, 17,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
      "         12, 13, 14, 15, 16, 17,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
      "         15, 16, 17,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  5,\n",
      "          6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  6,  7,  8,  9, 10, 11,\n",
      "         12, 13, 14, 15, 16, 17,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  8,\n",
      "          9, 10, 11, 12, 13, 14, 15, 16, 17,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         10, 11, 12, 13, 14, 15, 16, 17, 11, 12, 13, 14, 15, 16, 17, 12, 13, 14,\n",
      "         15, 16, 17, 13, 14, 15, 16, 17, 14, 15, 16, 17, 15, 16, 17, 16, 17, 17],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  2,\n",
      "          3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  3,  4,  5,\n",
      "          6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  4,  5,  6,  7,  8,  9,\n",
      "         10, 11, 12, 13, 14, 15, 16, 17,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
      "         15, 16, 17,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  7,  8,  9,\n",
      "         10, 11, 12, 13, 14, 15, 16, 17,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "          9, 10, 11, 12, 13, 14, 15, 16, 17, 10, 11, 12, 13, 14, 15, 16, 17, 11,\n",
      "         12, 13, 14, 15, 16, 17, 12, 13, 14, 15, 16, 17, 13, 14, 15, 16, 17, 14,\n",
      "         15, 16, 17, 15, 16, 17, 16, 17, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "          2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,\n",
      "          5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,\n",
      "          7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11,\n",
      "         11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15, 16]])}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate Samples\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_new_tr \u001b[38;5;241m=\u001b[39m \u001b[43msampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreward_sampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxt_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ep_traj=True,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36msampling\u001b[0;34m(config, model, xt_traj, ep_traj, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msampling\u001b[39m(\n\u001b[1;32m      2\u001b[0m         config: OmegaConf,\n\u001b[1;32m      3\u001b[0m         model: flowmol\u001b[38;5;241m.\u001b[39mFlowMol,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m         device: torch\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     ):\n\u001b[0;32m----> 8\u001b[0m     new_molecules \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_random_sizes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_molecules\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_integration_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxt_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxt_traj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mep_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mep_traj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_molecules\n",
      "File \u001b[0;32m~/MasterThesis/v02/flowmol/models/flowmol.py:450\u001b[0m, in \u001b[0;36mFlowMol.sample_random_sizes\u001b[0;34m(self, n_molecules, device, stochasticity, high_confidence_threshold, xt_traj, ep_traj, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# get the number of atoms that will be in each molecules\u001b[39;00m\n\u001b[1;32m    449\u001b[0m atoms_per_molecule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_n_atoms(n_molecules)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43matoms_per_molecule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstochasticity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstochasticity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhigh_confidence_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhigh_confidence_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxt_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxt_traj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mep_traj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mep_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MasterThesis/v02/flowmol/models/flowmol.py:488\u001b[0m, in \u001b[0;36mFlowMol.sample\u001b[0;34m(self, n_atoms, n_timesteps, device, stochasticity, high_confidence_threshold, xt_traj, ep_traj, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mprint\u001b[39m(n_atoms)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_idxs_dict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_idxs_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;66;03m# construct a graph for each molecule\u001b[39;00m\n\u001b[1;32m    490\u001b[0m g \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate Samples\n",
    "x_new_tr = sampling(\n",
    "    config.reward_sampling,\n",
    "    copy.deepcopy(gen_model),\n",
    "    xt_traj=True,\n",
    "    # ep_traj=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f32cc3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<flowmol.analysis.molecule_builder.SampledMolecule at 0x32fdb4790>,\n",
       " <flowmol.analysis.molecule_builder.SampledMolecule at 0x32fdb4700>,\n",
       " <flowmol.analysis.molecule_builder.SampledMolecule at 0x3200e9580>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad419ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31cd296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tr = x_new_tr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e92d6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "046d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = steps = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44e0ec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 1, 5, 5, 9])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx = np.random.choice(k, size=x, replace=True)\n",
    "idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "57c1104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = [i for i in range(1,10)]\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1b233e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.insert(0,losses[0])\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ae7b2f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3eb5c295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=23, num_edges=506,\n",
       "      ndata_schemes={'x_0': Scheme(shape=(3,), dtype=torch.float32), 'a_0': Scheme(shape=(6,), dtype=torch.float32), 'c_0': Scheme(shape=(7,), dtype=torch.float32), 'x_t': Scheme(shape=(3,), dtype=torch.float32), 'a_t': Scheme(shape=(6,), dtype=torch.float32), 'c_t': Scheme(shape=(7,), dtype=torch.float32), 'x_1_pred': Scheme(shape=(3,), dtype=torch.float32), 'a_1_pred': Scheme(shape=(6,), dtype=torch.float32), 'c_1_pred': Scheme(shape=(7,), dtype=torch.float32), 'x_1': Scheme(shape=(3,), dtype=torch.float32), 'a_1': Scheme(shape=(6,), dtype=torch.float32), 'c_1': Scheme(shape=(7,), dtype=torch.float32)}\n",
       "      edata_schemes={'e_0': Scheme(shape=(6,), dtype=torch.float32), 'e_t': Scheme(shape=(6,), dtype=torch.float32), 'e_1_pred': Scheme(shape=(6,), dtype=torch.float32), 'e_1': Scheme(shape=(6,), dtype=torch.float32), 'ue_mask': Scheme(shape=(), dtype=torch.bool)})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_t = sample_tr.g\n",
    "g_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "22a0086f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e_0': tensor([[0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.]]), 'e_t': tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.]]), 'e_1_pred': tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.]]), 'e_1': tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.]]), 'ue_mask': tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False])}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_t.edata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e956b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d596c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x330b07cf0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tr.rdkit_mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4970d861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "torch.Size([40, 23, 3])\n",
      "x_1_pred\n",
      "torch.Size([39, 23, 3])\n",
      "a\n",
      "torch.Size([40, 23, 6])\n",
      "a_1_pred\n",
      "torch.Size([39, 23, 6])\n",
      "c\n",
      "torch.Size([40, 23, 7])\n",
      "c_1_pred\n",
      "torch.Size([39, 23, 7])\n",
      "e\n",
      "torch.Size([40, 506, 6])\n",
      "e_1_pred\n",
      "torch.Size([39, 506, 6])\n"
     ]
    }
   ],
   "source": [
    "for k, v in sample_tr.traj_frames.items():\n",
    "    print(k)\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "66ecd58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "from flowmol.data_processing.utils import build_edge_idxs\n",
    "\n",
    "def build_graphs_from_traj(traj_frames):\n",
    "    x = traj_frames['x']       # [T, N, 3]\n",
    "    a = traj_frames['a']       # [T, N, 6]\n",
    "    c = traj_frames['c']       # [T, N, 7]\n",
    "    e = traj_frames['e']       # [T, E, 6]\n",
    "    \n",
    "    T, N, _ = x.shape\n",
    "    _, E, _ = e.shape\n",
    "\n",
    "    graphs = []\n",
    "    for t in range(T):\n",
    "        edge_idx = build_edge_idxs(N)  # assumed to return a tuple (src, dst) each of shape [E]\n",
    "\n",
    "        g = dgl.graph((edge_idx[0],edge_idx[1]), num_nodes=N)\n",
    "\n",
    "        g.ndata['x'] = x[t]       # [N, 3]\n",
    "        g.ndata['a'] = a[t]      # [N, 6]\n",
    "        g.ndata['c'] = c[t]    # [N, 7]\n",
    "        g.edata['e'] = e[t]      # [E, 6]\n",
    "\n",
    "        graphs.append(g)\n",
    "    \n",
    "    return graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f4a5c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = build_graphs_from_traj(sample_tr.traj_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "46bdeb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=23, num_edges=506,\n",
       "      ndata_schemes={'x': Scheme(shape=(3,), dtype=torch.float32), 'a': Scheme(shape=(6,), dtype=torch.float32), 'c': Scheme(shape=(7,), dtype=torch.float32)}\n",
       "      edata_schemes={'e': Scheme(shape=(6,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4b9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.1830e-08, 3.6281e-08, 2.5915e-09])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].ndata['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99718424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252a557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4cb9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87777ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c378977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23370bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27d0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a4be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
